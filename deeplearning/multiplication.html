

<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiplication &#8212; NengoExamples 22.1.22.dev0 docs</title>
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
<link href="https://fonts.googleapis.com/css?family=IBM+Plex+Sans:400,400i,600|Rajdhani:700&display=swap" rel="stylesheet">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.2/css/all.css" integrity="sha384-oS3vJWv+0UjzBfQzYUhtDYW+Pj2yciDJxpsK1OYPAYjqT085Qq/1cq5FLXAZQ7Ay" crossorigin="anonymous">
<link rel="stylesheet" href="https://www.nengo.ai/css/bootstrap.css" type="text/css">
<style>
  body .title-bar,
  body .documentation-source h1:after {
    background-color: #a8acaf;
  }
</style>
<!-- Google Tag Manager -->
<script>
 (function (w, d, s, l, i) {
   w[l] = w[l] || [];
   w[l].push({ "gtm.start": new Date().getTime(), event: "gtm.js" });
   var f = d.getElementsByTagName(s)[0],
       j = d.createElement(s),
       dl = l != "dataLayer" ? "&l=" + l : "";
   j.async = true;
   j.src = "https://www.googletagmanager.com/gtm.js?id=" + i + dl;
   f.parentNode.insertBefore(j, f);
 })(window, document, "script", "dataLayer", "GTM-KWCR2HN");
</script>
<!-- End Google Tag Manager -->
<script src="https://code.jquery.com/jquery-3.3.1.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
<script src="https://unpkg.com/scrollreveal"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/stickyfill/2.1.0/stickyfill.min.js"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/js/bootstrap.min.js" integrity="sha384-smHYKdLADwkXOn1EmN1qk/HfnUcbVRZyYmZ4qpPea6sjB/pTJ0euyQp0Mk8ck+5T" crossorigin="anonymous"></script>
<!-- From basic/layout.html -->
<script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
  
  
<script src="../_static/underscore.js"></script>
  
  
<script src="../_static/doctools.js"></script>
  
  
<script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
  
  
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  
  
<script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Optimizing Existing Networks" href="circularconvolution-softlif.html" />
<link rel="stylesheet" type="text/css" href="../_static/custom.css">


<meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">

  </head><body class="bg-dark">

<header class="fixed-top header-top shadow-sm">
  <nav class="navbar navbar-expand-md navbar-light bg-white">
    <a class="navbar-brand" href="https://www.nengo.ai/">
      <img
        src="https://www.nengo.ai/design/_images/general-full-light.svg"
        alt="Nengo"
        class="logo"
      />
    </a>
    <button
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbar-collapse"
      aria-controls="navbar-collapse"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbar-collapse">
      <ul class="navbar-nav ml-auto">
        <li class="nav-item">
          <a class="nav-link" href="https://www.nengo.ai/">What is Nengo?</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://www.nengo.ai/examples/">Examples</a>
        </li>
        <li class="nav-item dropdown active">
          <a
            class="nav-link dropdown-toggle"
            id="navbar-dropdown-docs"
            data-toggle="dropdown"
            aria-haspopup="true"
            aria-expanded="false"
            href="#"
            >Documentation</a
          >
          <div
            class="dropdown-menu shadow-lg border-0"
            aria-labelledby="navbar-dropdown-docs"
          >
            
            <a class="dropdown-item" href="https://www.nengo.ai/nengo/">Nengo core</a>
            <a class="dropdown-item" href="https://github.com/nengo/nengo-gui/">NengoGUI</a>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-dl/">NengoDL</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-spa/">NengoSPA</a>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-extras/">NengoExtras</a>
            <a class="dropdown-item" href="https://arvoelke.github.io/nengolib-docs/">Nengolib</a>
            <a class="dropdown-item" href="https://www.nengo.ai/keras-spiking">KerasSpiking</a>
            <a class="dropdown-item" href="https://www.nengo.ai/pytorch-spiking">PyTorchSpiking</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-fpga/">NengoFPGA</a>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-loihi/">NengoLoihi</a>
            <a class="dropdown-item" href="https://labs.nengo.ai/nengo-ocl/">NengoOCL</a>
            <a class="dropdown-item" href="https://github.com/project-rig/nengo_spinnaker">NengoSpiNNaker</a>
            <a class="dropdown-item" href="https://github.com/nengo-labs/nengo-mpi">NengoMPI</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/documentation/"
              >All documentation</a
            >
          </div>
        </li>
        <li class="nav-item dropdown">
          <a
            class="nav-link dropdown-toggle"
            id="navbar-dropdown-community"
            data-toggle="dropdown"
            aria-haspopup="true"
            aria-expanded="false"
            href="#"
            >Community</a
          >
          <div
            class="dropdown-menu shadow-lg border-0"
            aria-labelledby="navbar-dropdown-community"
          >
            <a class="dropdown-item" href="https://forum.nengo.ai">Forum</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/people/"
              >People</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/summer-school/"
              >Summer school</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/contributing/"
              >Contributing</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/publications/"
              >Publications</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/videos/"
              >Videos</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/conduct/"
              >Code of conduct</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/caa/">CAA</a>
          </div>
        </li>
        <li class="nav-item">
          <a
            class="nav-link btn btn-success btn-sm text-white"
            href="https://www.nengo.ai/getting-started/"
            >Getting started</a
          >
        </li>
      </ul>
    </div>
  </nav>
</header>
<div class="main-content gradient-top">
  <div class="container-fluid">
    <div class="row"><a class="toggle-sidenav d-block d-md-none" href="#"
  ><i class="icon-close fa fa-fw fa-arrow-left"></i
  ><i class="icon-open fa fa-fw fa-arrow-right"></i
></a>
<div role="complementary" class="sidenav col-4 col-xl-3 p-0 border-right">
  <h3 class="pt-5 px-5">
    <a href="../index.html">
      <img
        class="img-fluid documentation-image"
        src="https://www.nengo.ai/design/_images/general-full-light.svg"
        alt="NengoExamples"
      />
    </a>
  </h3>
<form class="px-5 py-3 my-0 border-bottom" action="../search.html" method="get">
  <div class="form-group form-group-single">
    <input type="text" name="q" class="form-control" placeholder="Search" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
    <button type="submit" class="btn btn-link">
      <img src="https://www.nengo.ai/img/icon-search.svg" alt="Go" />
    </button>
  </div>
</form><div class="p-5 toctree">
  
    <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../loihi/index.html">NengoLoihi</a></li>
<li class="toctree-l1"><a class="reference internal" href="../htbab/index.html">How to Build a Brain</a></li>
<li class="toctree-l1"><a class="reference internal" href="../core/index.html">NengoCore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ablate/index.html">Ablating neurons</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Deep learning</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="index.html#examples">Examples</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="circularconvolution-softlif.html">Optimizing Existing Networks</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Multiplication</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="index.html#requirements">Requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#license">License</a></li>
</ul>
</li>
</ul>

  
  </div>
  
  <form class="p-5 my-0 border-top">
    <div class="form-group">
      <label class="text-gray">Version:</label>
      <select class="custom-select" onchange="switchVersion(this);">
        
        
        <option selected>latest</option>
        
        
      </select>
    </div>
  </form>
  
</div>
      

      <div class="col-12 col-md-8 col-xl-9">
        <div class="container">
          <div class="row">
            <div class="col-10 offset-1 pb-5 documentation-source" role="main">
              
              
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<div class="section" id="Multiplication">
<h1>Multiplication<a class="headerlink" href="#Multiplication" title="Permalink to this headline">¶</a></h1>
<p>A quick and easy example to start off with is to build a toy model which takes in two numbers, and outputs the result. Although the model doesn’t accomplish anything significant the same techniques can be used to model and train much larger and complex networks.</p>
<p><code class="docutils literal notranslate"><span class="pre">Numpy</span></code> is seeded to allow deterministic results, this seeding has no relevance to the architecture or the training of the network</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">nengo</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">nengo_dl</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="Architecture">
<h2>Architecture<a class="headerlink" href="#Architecture" title="Permalink to this headline">¶</a></h2>
<p>We connect two input nodes (<code class="docutils literal notranslate"><span class="pre">i_1</span></code>, <code class="docutils literal notranslate"><span class="pre">i_2</span></code>), both of which generate random numbers, to ensemble <code class="docutils literal notranslate"><span class="pre">a</span></code>. Then <code class="docutils literal notranslate"><span class="pre">a</span></code> is connected to a second ensemble <code class="docutils literal notranslate"><span class="pre">b</span></code>, which we probe for the output.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Network</span><span class="p">()</span> <span class="k">as</span> <span class="n">net</span><span class="p">:</span>

    <span class="n">net</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="n">nengo</span><span class="o">.</span><span class="n">Ensemble</span><span class="p">]</span><span class="o">.</span><span class="n">neuron_type</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">RectifiedLinear</span><span class="p">()</span>
    <span class="n">net</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="n">nengo</span><span class="o">.</span><span class="n">Ensemble</span><span class="p">]</span><span class="o">.</span><span class="n">gain</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">dists</span><span class="o">.</span><span class="n">Choice</span><span class="p">([</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">net</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="n">nengo</span><span class="o">.</span><span class="n">Ensemble</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">dists</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">]</span><span class="o">.</span><span class="n">synapse</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="n">i_1</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">output</span><span class="o">=</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">())</span>
    <span class="n">i_2</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">output</span><span class="o">=</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">())</span>

    <span class="n">a</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Ensemble</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Ensemble</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">i_1</span><span class="p">,</span> <span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">i_2</span><span class="p">,</span> <span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">function</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="n">i_1_probe</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Probe</span><span class="p">(</span><span class="n">i_1</span><span class="p">)</span>
    <span class="n">i_2_probe</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Probe</span><span class="p">(</span><span class="n">i_2</span><span class="p">)</span>
    <span class="n">output_probe</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Probe</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Before we train the network the output is approximately zero, since that is the function we specified on the connection from <code class="docutils literal notranslate"><span class="pre">a</span></code> to <code class="docutils literal notranslate"><span class="pre">b</span></code>. However we don’t want that output, so we need to train the network to multiply the inputs.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_steps</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">minibatch_size</span> <span class="o">=</span> <span class="mi">256</span>
<span class="c1"># Showing the output of the model pre training</span>
<span class="k">with</span> <span class="n">nengo_dl</span><span class="o">.</span><span class="n">Simulator</span><span class="p">(</span><span class="n">net</span><span class="p">)</span> <span class="k">as</span> <span class="n">sim</span><span class="p">:</span>
    <span class="n">sim</span><span class="o">.</span><span class="n">run_steps</span><span class="p">(</span><span class="n">n_steps</span><span class="p">)</span>
    <span class="n">true_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">i_1_probe</span><span class="p">],</span> <span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">i_2_probe</span><span class="p">])</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Pre-Training&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">output_probe</span><span class="p">],</span> <span class="s2">&quot;g&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;predicted value&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">true_value</span><span class="p">,</span> <span class="s2">&quot;m&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;true value&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Build finished in 0:00:00
Optimization finished in 0:00:00
Construction finished in 0:00:00
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2022-01-21 11:53:06.875694: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Simulation finished in 0:00:01
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/deeplearning_multiplication_5_3.png" src="../_images/deeplearning_multiplication_5_3.png" />
</div>
</div>
<p>To train the network we generate training feeds which consist of two batches of random numbers (the inputs) and then the result of those batches multiplied together (the outputs). Additionally we generate some test data to easily track the progress of the network throughout training.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">nengo_dl</span><span class="o">.</span><span class="n">Simulator</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">minibatch_size</span><span class="o">=</span><span class="n">minibatch_size</span><span class="p">)</span> <span class="k">as</span> <span class="n">sim</span><span class="p">:</span>
    <span class="c1"># This feed is used as the &quot;test&quot; data</span>
    <span class="c1"># It&#39;s run through the network after every iteration</span>
    <span class="c1"># to allow easy visulization of how the output is changing</span>
    <span class="n">test_inputs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">i_1</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">minibatch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
        <span class="n">i_2</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">minibatch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
    <span class="p">}</span>
    <span class="n">test_targets</span> <span class="o">=</span> <span class="p">{</span><span class="n">output_probe</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">test_inputs</span><span class="p">[</span><span class="n">i_1</span><span class="p">],</span> <span class="n">test_inputs</span><span class="p">[</span><span class="n">i_2</span><span class="p">])}</span>

    <span class="c1"># running through 10 rounds of training/testing</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">sim</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;mse&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">MomentumOptimizer</span><span class="p">(</span><span class="mf">5e-2</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
        <span class="c1"># check performance on test set</span>
        <span class="n">sim</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">test_inputs</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;LOSS: </span><span class="si">{</span><span class="n">sim</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_inputs</span><span class="p">,</span> <span class="n">test_targets</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">output_probe</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

        <span class="c1"># run training</span>
        <span class="n">input_feed</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">i_1</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">minibatch_size</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="n">i_2</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">minibatch_size</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
        <span class="p">}</span>
        <span class="n">output_feed</span> <span class="o">=</span> <span class="p">{</span><span class="n">output_probe</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">input_feed</span><span class="p">[</span><span class="n">i_1</span><span class="p">],</span> <span class="n">input_feed</span><span class="p">[</span><span class="n">i_2</span><span class="p">])}</span>
        <span class="n">sim</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">input_feed</span><span class="p">,</span> <span class="n">output_feed</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
        <span class="n">sim</span><span class="o">.</span><span class="n">soft_reset</span><span class="p">(</span><span class="n">include_probes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># check final performance on test set</span>
    <span class="n">sim</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">test_inputs</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;LOSS: </span><span class="si">{</span><span class="n">sim</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_inputs</span><span class="p">,</span> <span class="n">test_targets</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">output_probe</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Build finished in 0:00:00
Optimization finished in 0:00:00
Construction finished in 0:00:00
1/1 [==============================] - 1s 577ms/step - loss: 0.1043 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 0.1043
LOSS: {&#39;loss&#39;: 0.1042896956205368, &#39;probe_loss&#39;: 0.0, &#39;probe_1_loss&#39;: 0.0, &#39;probe_2_loss&#39;: 0.1042896956205368}
Epoch 1/12
5/5 [==============================] - 1s 6ms/step - loss: 0.2337 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 0.2337
Epoch 2/12
5/5 [==============================] - 0s 5ms/step - loss: 0.3275 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 0.3275
Epoch 3/12
5/5 [==============================] - 0s 6ms/step - loss: 0.1308 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 0.1308
Epoch 4/12
5/5 [==============================] - 0s 8ms/step - loss: 0.0706 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 0.0706
Epoch 5/12
5/5 [==============================] - 0s 8ms/step - loss: 0.0579 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 0.0579
Epoch 6/12
5/5 [==============================] - 0s 9ms/step - loss: 0.0205 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 0.0205
Epoch 7/12
5/5 [==============================] - 0s 9ms/step - loss: 0.0147 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 0.0147
Epoch 8/12
5/5 [==============================] - 0s 10ms/step - loss: 0.0066 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 0.0066
Epoch 9/12
5/5 [==============================] - 0s 8ms/step - loss: 0.0037 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 0.0037
Epoch 10/12
5/5 [==============================] - 0s 7ms/step - loss: 0.0022 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 0.0022
Epoch 11/12
5/5 [==============================] - 0s 7ms/step - loss: 0.0013 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 0.0013
Epoch 12/12
5/5 [==============================] - 0s 9ms/step - loss: 5.4811e-04 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 5.4811e-04
1/1 [==============================] - 0s 25ms/step - loss: 2.6955e-04 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 2.6955e-04
LOSS: {&#39;loss&#39;: 0.0002695529256016016, &#39;probe_loss&#39;: 0.0, &#39;probe_1_loss&#39;: 0.0, &#39;probe_2_loss&#39;: 0.0002695529256016016}
Epoch 1/12
5/5 [==============================] - 0s 4ms/step - loss: 4.0840e-04 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 4.0840e-04
Epoch 2/12
5/5 [==============================] - 0s 5ms/step - loss: 2.4546e-04 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 2.4546e-04
Epoch 3/12
5/5 [==============================] - 0s 4ms/step - loss: 2.5043e-04 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 2.5043e-04
Epoch 4/12
5/5 [==============================] - 0s 4ms/step - loss: 2.0081e-04 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 2.0081e-04
Epoch 5/12
5/5 [==============================] - 0s 5ms/step - loss: 1.5814e-04 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 1.5814e-04
Epoch 6/12
5/5 [==============================] - 0s 6ms/step - loss: 1.1901e-04 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 1.1901e-04
Epoch 7/12
5/5 [==============================] - 0s 7ms/step - loss: 1.1392e-04 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 1.1392e-04
Epoch 8/12
5/5 [==============================] - 0s 7ms/step - loss: 1.0630e-04 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 1.0630e-04
Epoch 9/12
5/5 [==============================] - 0s 8ms/step - loss: 1.0858e-04 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 1.0858e-04
Epoch 10/12
5/5 [==============================] - 0s 8ms/step - loss: 1.0353e-04 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 1.0353e-04
Epoch 11/12
5/5 [==============================] - 0s 10ms/step - loss: 1.0179e-04 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 1.0179e-04
Epoch 12/12
5/5 [==============================] - 0s 9ms/step - loss: 1.0156e-04 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 1.0156e-04
1/1 [==============================] - 0s 20ms/step - loss: 1.1966e-04 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 1.1966e-04
LOSS: {&#39;loss&#39;: 0.00011965574230998755, &#39;probe_loss&#39;: 0.0, &#39;probe_1_loss&#39;: 0.0, &#39;probe_2_loss&#39;: 0.00011965574230998755}
Epoch 1/12
5/5 [==============================] - 0s 4ms/step - loss: 1.1315e-04 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 1.1315e-04
Epoch 2/12
5/5 [==============================] - 0s 5ms/step - loss: 1.1112e-04 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 1.1112e-04
Epoch 3/12
5/5 [==============================] - 0s 6ms/step - loss: 1.0973e-04 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 1.0973e-04
Epoch 4/12
5/5 [==============================] - 0s 5ms/step - loss: 1.0618e-04 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 1.0618e-04
Epoch 5/12
5/5 [==============================] - 0s 4ms/step - loss: 1.0484e-04 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 1.0484e-04
Epoch 6/12
5/5 [==============================] - 0s 5ms/step - loss: 1.0146e-04 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 1.0146e-04
Epoch 7/12
5/5 [==============================] - 0s 5ms/step - loss: 1.0535e-04 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 1.0535e-04
Epoch 8/12
5/5 [==============================] - 0s 5ms/step - loss: 1.0335e-04 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 1.0335e-04
Epoch 9/12
5/5 [==============================] - 0s 5ms/step - loss: 9.7415e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 9.7415e-05
Epoch 10/12
5/5 [==============================] - 0s 6ms/step - loss: 9.5973e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 9.5973e-05
Epoch 11/12
5/5 [==============================] - 0s 5ms/step - loss: 9.3890e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 9.3890e-05
Epoch 12/12
5/5 [==============================] - 0s 5ms/step - loss: 9.3631e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 9.3631e-05
1/1 [==============================] - 0s 18ms/step - loss: 8.6050e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 8.6050e-05
LOSS: {&#39;loss&#39;: 8.604974573245272e-05, &#39;probe_loss&#39;: 0.0, &#39;probe_1_loss&#39;: 0.0, &#39;probe_2_loss&#39;: 8.604974573245272e-05}
Epoch 1/12
5/5 [==============================] - 0s 4ms/step - loss: 8.9583e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 8.9583e-05
Epoch 2/12
5/5 [==============================] - 0s 4ms/step - loss: 8.8900e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 8.8900e-05
Epoch 3/12
5/5 [==============================] - 0s 5ms/step - loss: 9.5365e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 9.5365e-05
Epoch 4/12
5/5 [==============================] - 0s 4ms/step - loss: 8.9794e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 8.9794e-05
Epoch 5/12
5/5 [==============================] - 0s 5ms/step - loss: 8.5178e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 8.5178e-05
Epoch 6/12
5/5 [==============================] - 0s 5ms/step - loss: 8.7636e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 8.7636e-05
Epoch 7/12
5/5 [==============================] - 0s 4ms/step - loss: 8.3952e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 8.3952e-05
Epoch 8/12
5/5 [==============================] - 0s 4ms/step - loss: 8.2921e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 8.2921e-05
Epoch 9/12
5/5 [==============================] - 0s 4ms/step - loss: 8.3131e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 8.3131e-05
Epoch 10/12
5/5 [==============================] - 0s 4ms/step - loss: 8.4504e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 8.4504e-05
Epoch 11/12
5/5 [==============================] - 0s 6ms/step - loss: 8.3002e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 8.3002e-05
Epoch 12/12
5/5 [==============================] - 0s 7ms/step - loss: 8.0583e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 8.0583e-05
1/1 [==============================] - 0s 18ms/step - loss: 7.4353e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 7.4353e-05
LOSS: {&#39;loss&#39;: 7.435342558892444e-05, &#39;probe_loss&#39;: 0.0, &#39;probe_1_loss&#39;: 0.0, &#39;probe_2_loss&#39;: 7.435342558892444e-05}
Epoch 1/12
5/5 [==============================] - 0s 4ms/step - loss: 8.6869e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 8.6869e-05
Epoch 2/12
5/5 [==============================] - 0s 5ms/step - loss: 8.6029e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 8.6029e-05
Epoch 3/12
5/5 [==============================] - 0s 5ms/step - loss: 8.5612e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 8.5612e-05
Epoch 4/12
5/5 [==============================] - 0s 7ms/step - loss: 8.5974e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 8.5974e-05
Epoch 5/12
5/5 [==============================] - 0s 8ms/step - loss: 8.2408e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 8.2408e-05
Epoch 6/12
5/5 [==============================] - 0s 6ms/step - loss: 8.1877e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 8.1877e-05
Epoch 7/12
5/5 [==============================] - 0s 5ms/step - loss: 8.6833e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 8.6833e-05
Epoch 8/12
5/5 [==============================] - 0s 5ms/step - loss: 8.1718e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 8.1718e-05
Epoch 9/12
5/5 [==============================] - 0s 5ms/step - loss: 8.2583e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 8.2583e-05
Epoch 10/12
5/5 [==============================] - 0s 7ms/step - loss: 8.0660e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 8.0660e-05
Epoch 11/12
5/5 [==============================] - 0s 5ms/step - loss: 8.1962e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 8.1962e-05
Epoch 12/12
5/5 [==============================] - 0s 5ms/step - loss: 8.0052e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 8.0052e-05
1/1 [==============================] - 0s 20ms/step - loss: 6.7072e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 6.7072e-05
LOSS: {&#39;loss&#39;: 6.707150168949738e-05, &#39;probe_loss&#39;: 0.0, &#39;probe_1_loss&#39;: 0.0, &#39;probe_2_loss&#39;: 6.707150168949738e-05}
Epoch 1/12
5/5 [==============================] - 0s 4ms/step - loss: 6.5084e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 6.5084e-05
Epoch 2/12
5/5 [==============================] - 0s 4ms/step - loss: 6.4651e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 6.4651e-05
Epoch 3/12
5/5 [==============================] - 0s 4ms/step - loss: 6.4055e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 6.4055e-05
Epoch 4/12
5/5 [==============================] - 0s 4ms/step - loss: 6.5517e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 6.5517e-05
Epoch 5/12
5/5 [==============================] - 0s 5ms/step - loss: 6.5879e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 6.5879e-05
Epoch 6/12
5/5 [==============================] - 0s 5ms/step - loss: 6.8302e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 6.8302e-05
Epoch 7/12
5/5 [==============================] - 0s 6ms/step - loss: 6.4038e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 6.4038e-05
Epoch 8/12
5/5 [==============================] - 0s 6ms/step - loss: 6.2072e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 6.2072e-05
Epoch 9/12
5/5 [==============================] - 0s 7ms/step - loss: 6.2071e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 6.2071e-05
Epoch 10/12
5/5 [==============================] - 0s 6ms/step - loss: 6.2098e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 6.2098e-05
Epoch 11/12
5/5 [==============================] - 0s 10ms/step - loss: 6.0936e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 6.0936e-05
Epoch 12/12
5/5 [==============================] - 0s 5ms/step - loss: 6.2646e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 6.2646e-05
1/1 [==============================] - 0s 22ms/step - loss: 6.6837e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 6.6837e-05
LOSS: {&#39;loss&#39;: 6.683747778879479e-05, &#39;probe_loss&#39;: 0.0, &#39;probe_1_loss&#39;: 0.0, &#39;probe_2_loss&#39;: 6.683747778879479e-05}
Epoch 1/12
5/5 [==============================] - 0s 4ms/step - loss: 7.7861e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 7.7861e-05
Epoch 2/12
5/5 [==============================] - 0s 4ms/step - loss: 7.9567e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 7.9567e-05
Epoch 3/12
5/5 [==============================] - 0s 4ms/step - loss: 7.0654e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 7.0654e-05
Epoch 4/12
5/5 [==============================] - 0s 4ms/step - loss: 7.5837e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 7.5837e-05
Epoch 5/12
5/5 [==============================] - 0s 5ms/step - loss: 7.4511e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 7.4511e-05
Epoch 6/12
5/5 [==============================] - 0s 5ms/step - loss: 7.1558e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 7.1558e-05
Epoch 7/12
5/5 [==============================] - 0s 5ms/step - loss: 7.0029e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 7.0029e-05
Epoch 8/12
5/5 [==============================] - 0s 5ms/step - loss: 6.9910e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 6.9910e-05
Epoch 9/12
5/5 [==============================] - 0s 5ms/step - loss: 6.7262e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 6.7262e-05
Epoch 10/12
5/5 [==============================] - 0s 6ms/step - loss: 6.7590e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 6.7590e-05
Epoch 11/12
5/5 [==============================] - 0s 5ms/step - loss: 6.7905e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 6.7905e-05
Epoch 12/12
5/5 [==============================] - 0s 6ms/step - loss: 6.6173e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 6.6173e-05
1/1 [==============================] - 0s 18ms/step - loss: 5.3877e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 5.3877e-05
LOSS: {&#39;loss&#39;: 5.387669807532802e-05, &#39;probe_loss&#39;: 0.0, &#39;probe_1_loss&#39;: 0.0, &#39;probe_2_loss&#39;: 5.387669807532802e-05}
Epoch 1/12
5/5 [==============================] - 0s 4ms/step - loss: 6.5790e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 6.5790e-05
Epoch 2/12
5/5 [==============================] - 0s 5ms/step - loss: 6.5030e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 6.5030e-05
Epoch 3/12
5/5 [==============================] - 0s 4ms/step - loss: 6.1451e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 6.1451e-05
Epoch 4/12
5/5 [==============================] - 0s 4ms/step - loss: 6.2528e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 6.2528e-05
Epoch 5/12
5/5 [==============================] - 0s 3ms/step - loss: 6.0573e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 6.0573e-05
Epoch 6/12
5/5 [==============================] - 0s 5ms/step - loss: 6.6364e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 6.6364e-05
Epoch 7/12
5/5 [==============================] - 0s 6ms/step - loss: 6.3155e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 6.3155e-05
Epoch 8/12
5/5 [==============================] - 0s 5ms/step - loss: 6.6353e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 6.6353e-05
Epoch 9/12
5/5 [==============================] - 0s 6ms/step - loss: 6.7410e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 6.7410e-05
Epoch 10/12
5/5 [==============================] - 0s 6ms/step - loss: 6.3646e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 6.3646e-05
Epoch 11/12
5/5 [==============================] - 0s 6ms/step - loss: 6.0384e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 6.0384e-05
Epoch 12/12
5/5 [==============================] - 0s 6ms/step - loss: 5.9496e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 5.9496e-05
1/1 [==============================] - 0s 22ms/step - loss: 5.7556e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 5.7556e-05
LOSS: {&#39;loss&#39;: 5.7556455431040376e-05, &#39;probe_loss&#39;: 0.0, &#39;probe_1_loss&#39;: 0.0, &#39;probe_2_loss&#39;: 5.7556455431040376e-05}
Epoch 1/12
5/5 [==============================] - 0s 5ms/step - loss: 6.0345e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 6.0345e-05
Epoch 2/12
5/5 [==============================] - 0s 5ms/step - loss: 5.7973e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 5.7973e-05
Epoch 3/12
5/5 [==============================] - 0s 4ms/step - loss: 5.5279e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 5.5279e-05
Epoch 4/12
5/5 [==============================] - 0s 5ms/step - loss: 5.4666e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 5.4666e-05
Epoch 5/12
5/5 [==============================] - 0s 5ms/step - loss: 5.6673e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 5.6673e-05
Epoch 6/12
5/5 [==============================] - 0s 5ms/step - loss: 5.3452e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 5.3452e-05
Epoch 7/12
5/5 [==============================] - 0s 4ms/step - loss: 5.2916e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 5.2916e-05
Epoch 8/12
5/5 [==============================] - 0s 4ms/step - loss: 5.3558e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 5.3558e-05
Epoch 9/12
5/5 [==============================] - 0s 4ms/step - loss: 5.2590e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 5.2590e-05
Epoch 10/12
5/5 [==============================] - 0s 4ms/step - loss: 5.2151e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 5.2151e-05
Epoch 11/12
5/5 [==============================] - 0s 4ms/step - loss: 5.2926e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 5.2926e-05
Epoch 12/12
5/5 [==============================] - 0s 6ms/step - loss: 5.2411e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 5.2411e-05
1/1 [==============================] - 0s 19ms/step - loss: 4.8881e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 4.8881e-05
LOSS: {&#39;loss&#39;: 4.888128751190379e-05, &#39;probe_loss&#39;: 0.0, &#39;probe_1_loss&#39;: 0.0, &#39;probe_2_loss&#39;: 4.888128751190379e-05}
Epoch 1/12
5/5 [==============================] - 0s 4ms/step - loss: 5.4918e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 5.4918e-05
Epoch 2/12
5/5 [==============================] - 0s 4ms/step - loss: 5.4579e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 5.4579e-05
Epoch 3/12
5/5 [==============================] - 0s 4ms/step - loss: 5.3743e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 5.3743e-05
Epoch 4/12
5/5 [==============================] - 0s 4ms/step - loss: 5.3452e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 5.3452e-05
Epoch 5/12
5/5 [==============================] - 0s 4ms/step - loss: 5.3543e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 5.3543e-05
Epoch 6/12
5/5 [==============================] - 0s 6ms/step - loss: 5.5079e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 5.5079e-05
Epoch 7/12
5/5 [==============================] - 0s 6ms/step - loss: 5.8177e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 5.8177e-05
Epoch 8/12
5/5 [==============================] - 0s 7ms/step - loss: 5.9010e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 5.9010e-05
Epoch 9/12
5/5 [==============================] - 0s 8ms/step - loss: 5.7728e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 5.7728e-05
Epoch 10/12
5/5 [==============================] - 0s 7ms/step - loss: 5.2985e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 5.2985e-05
Epoch 11/12
5/5 [==============================] - 0s 8ms/step - loss: 5.0936e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 5.0936e-05
Epoch 12/12
5/5 [==============================] - 0s 6ms/step - loss: 5.1032e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 5.1032e-05
1/1 [==============================] - 0s 17ms/step - loss: 4.5568e-05 - probe_loss: 0.0000e+00 - probe_1_loss: 0.0000e+00 - probe_2_loss: 4.5568e-05
LOSS: {&#39;loss&#39;: 4.5567761844722554e-05, &#39;probe_loss&#39;: 0.0, &#39;probe_1_loss&#39;: 0.0, &#39;probe_2_loss&#39;: 4.5567761844722554e-05}
</pre></div></div>
</div>
<p>We visualize the results by plotting the pre-trained, trained and ideal outputs next to each other</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Pre/Post Training Comparison&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span><span class="mi">50</span><span class="p">],</span> <span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;pre-training&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">10</span><span class="p">][:</span><span class="mi">50</span><span class="p">],</span> <span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;trained&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">test_targets</span><span class="p">[</span><span class="n">output_probe</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">()[:</span><span class="mi">50</span><span class="p">],</span> <span class="s2">&quot;m&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;ideal&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;matplotlib.legend.Legend at 0x7f00dd1d27f0&gt;
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/deeplearning_multiplication_9_1.png" src="../_images/deeplearning_multiplication_9_1.png" />
</div>
</div>
</div>
</div>


            </div>
          </div>
        </div>
      </div>

    </div>
  </div>
</div><footer class="text-light footer-main gradient-bottom">
  <p class="small text-center mb-0">
    <a class="no-hover-line" href="https://appliedbrainresearch.com">
      <img
        src="https://appliedbrainresearch.com/img/logo-blue-notext.svg"
        height="48"
      />
    </a>
    <a href="https://www.nengo.ai/">What is Nengo?</a>
    <a href="https://www.nengo.ai/examples/">Examples</a>
    <a href="https://www.nengo.ai/documentation/">Documentation</a>
    <a href="https://www.nengo.ai/getting-started/">Getting started</a>
    <a href="https://www.nengo.ai/privacy/">Privacy</a>
  </p>
  <p class="small text-center mb-0">&copy; Applied Brain Research</p>
</footer>
<script>
  function switchVersion(select) {
    var option = select.selectedOptions[0];
    if (option.hasAttribute("value")) {
      window.location = option.value;
    }
  }
</script>

<script>
  var elements = document.querySelectorAll('.sidenav');
  Stickyfill.add(elements);
</script>
<script>
  ScrollReveal().reveal(".fade-in", {
      scale: 0.85,
      duration: 1000,
      delay: 250,
      interval: 50
  });
</script>
<script>
  $('a.toggle-sidenav').on('click', function(e) {
    e.preventDefault();
    if ( $(this).hasClass('active') ) {
      $(this).removeClass('active');
      $('.sidenav').removeClass('open');
    } else {
      $(this).addClass('active');
      $('.sidenav').addClass('open');
    }
  });
</script>
<script>
  var lists = document.querySelectorAll('.toctree ul');
  lists.forEach((ul) => {
      ul.classList.add("nav");
  });
  var links = document.querySelectorAll('.toctree a');
  links.forEach((link) => {
      link.classList.add("nav-link");
  });
  $("body").scrollspy({target: ".sidenav"});
</script>
  </body>
</html>