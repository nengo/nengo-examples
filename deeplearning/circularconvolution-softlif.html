

<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Optimizing Existing Networks &#8212; NengoExamples 22.1.21.dev0 docs</title>
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
<link href="https://fonts.googleapis.com/css?family=IBM+Plex+Sans:400,400i,600|Rajdhani:700&display=swap" rel="stylesheet">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.2/css/all.css" integrity="sha384-oS3vJWv+0UjzBfQzYUhtDYW+Pj2yciDJxpsK1OYPAYjqT085Qq/1cq5FLXAZQ7Ay" crossorigin="anonymous">
<link rel="stylesheet" href="https://www.nengo.ai/css/bootstrap.css" type="text/css">
<style>
  body .title-bar,
  body .documentation-source h1:after {
    background-color: #a8acaf;
  }
</style>
<!-- Google Tag Manager -->
<script>
 (function (w, d, s, l, i) {
   w[l] = w[l] || [];
   w[l].push({ "gtm.start": new Date().getTime(), event: "gtm.js" });
   var f = d.getElementsByTagName(s)[0],
       j = d.createElement(s),
       dl = l != "dataLayer" ? "&l=" + l : "";
   j.async = true;
   j.src = "https://www.googletagmanager.com/gtm.js?id=" + i + dl;
   f.parentNode.insertBefore(j, f);
 })(window, document, "script", "dataLayer", "GTM-KWCR2HN");
</script>
<!-- End Google Tag Manager -->
<script src="https://code.jquery.com/jquery-3.3.1.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
<script src="https://unpkg.com/scrollreveal"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/stickyfill/2.1.0/stickyfill.min.js"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/js/bootstrap.min.js" integrity="sha384-smHYKdLADwkXOn1EmN1qk/HfnUcbVRZyYmZ4qpPea6sjB/pTJ0euyQp0Mk8ck+5T" crossorigin="anonymous"></script>
<!-- From basic/layout.html -->
<script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
  
  
<script src="../_static/underscore.js"></script>
  
  
<script src="../_static/doctools.js"></script>
  
  
<script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
  
  
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  
  
<script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Multiplication" href="multiplication.html" />
    <link rel="prev" title="Deep learning" href="index.html" />
<link rel="stylesheet" type="text/css" href="../_static/custom.css">


<meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">

  </head><body class="bg-dark">

<header class="fixed-top header-top shadow-sm">
  <nav class="navbar navbar-expand-md navbar-light bg-white">
    <a class="navbar-brand" href="https://www.nengo.ai/">
      <img
        src="https://www.nengo.ai/design/_images/general-full-light.svg"
        alt="Nengo"
        class="logo"
      />
    </a>
    <button
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbar-collapse"
      aria-controls="navbar-collapse"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbar-collapse">
      <ul class="navbar-nav ml-auto">
        <li class="nav-item">
          <a class="nav-link" href="https://www.nengo.ai/">What is Nengo?</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://www.nengo.ai/examples/">Examples</a>
        </li>
        <li class="nav-item dropdown active">
          <a
            class="nav-link dropdown-toggle"
            id="navbar-dropdown-docs"
            data-toggle="dropdown"
            aria-haspopup="true"
            aria-expanded="false"
            href="#"
            >Documentation</a
          >
          <div
            class="dropdown-menu shadow-lg border-0"
            aria-labelledby="navbar-dropdown-docs"
          >
            
            <a class="dropdown-item" href="https://www.nengo.ai/nengo/">Nengo core</a>
            <a class="dropdown-item" href="https://github.com/nengo/nengo-gui/">NengoGUI</a>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-dl/">NengoDL</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-spa/">NengoSPA</a>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-extras/">NengoExtras</a>
            <a class="dropdown-item" href="https://arvoelke.github.io/nengolib-docs/">Nengolib</a>
            <a class="dropdown-item" href="https://www.nengo.ai/keras-spiking">KerasSpiking</a>
            <a class="dropdown-item" href="https://www.nengo.ai/pytorch-spiking">PyTorchSpiking</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-fpga/">NengoFPGA</a>
            <a class="dropdown-item" href="https://www.nengo.ai/nengo-loihi/">NengoLoihi</a>
            <a class="dropdown-item" href="https://labs.nengo.ai/nengo-ocl/">NengoOCL</a>
            <a class="dropdown-item" href="https://github.com/project-rig/nengo_spinnaker">NengoSpiNNaker</a>
            <a class="dropdown-item" href="https://github.com/nengo-labs/nengo-mpi">NengoMPI</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/documentation/"
              >All documentation</a
            >
          </div>
        </li>
        <li class="nav-item dropdown">
          <a
            class="nav-link dropdown-toggle"
            id="navbar-dropdown-community"
            data-toggle="dropdown"
            aria-haspopup="true"
            aria-expanded="false"
            href="#"
            >Community</a
          >
          <div
            class="dropdown-menu shadow-lg border-0"
            aria-labelledby="navbar-dropdown-community"
          >
            <a class="dropdown-item" href="https://forum.nengo.ai">Forum</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://www.nengo.ai/people/"
              >People</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/summer-school/"
              >Summer school</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/contributing/"
              >Contributing</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/publications/"
              >Publications</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/videos/"
              >Videos</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/conduct/"
              >Code of conduct</a
            >
            <a class="dropdown-item" href="https://www.nengo.ai/caa/">CAA</a>
          </div>
        </li>
        <li class="nav-item">
          <a
            class="nav-link btn btn-success btn-sm text-white"
            href="https://www.nengo.ai/getting-started/"
            >Getting started</a
          >
        </li>
      </ul>
    </div>
  </nav>
</header>
<div class="main-content gradient-top">
  <div class="container-fluid">
    <div class="row"><a class="toggle-sidenav d-block d-md-none" href="#"
  ><i class="icon-close fa fa-fw fa-arrow-left"></i
  ><i class="icon-open fa fa-fw fa-arrow-right"></i
></a>
<div role="complementary" class="sidenav col-4 col-xl-3 p-0 border-right">
  <h3 class="pt-5 px-5">
    <a href="../index.html">
      <img
        class="img-fluid documentation-image"
        src="https://www.nengo.ai/design/_images/general-full-light.svg"
        alt="NengoExamples"
      />
    </a>
  </h3>
<form class="px-5 py-3 my-0 border-bottom" action="../search.html" method="get">
  <div class="form-group form-group-single">
    <input type="text" name="q" class="form-control" placeholder="Search" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
    <button type="submit" class="btn btn-link">
      <img src="https://www.nengo.ai/img/icon-search.svg" alt="Go" />
    </button>
  </div>
</form><div class="p-5 toctree">
  
    <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../loihi/index.html">NengoLoihi</a></li>
<li class="toctree-l1"><a class="reference internal" href="../htbab/index.html">How to Build a Brain</a></li>
<li class="toctree-l1"><a class="reference internal" href="../core/index.html">NengoCore</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ablate/index.html">Ablating neurons</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Deep learning</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="index.html#examples">Examples</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">Optimizing Existing Networks</a></li>
<li class="toctree-l3"><a class="reference internal" href="multiplication.html">Multiplication</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="index.html#requirements">Requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#license">License</a></li>
</ul>
</li>
</ul>

  
  </div>
  
  <form class="p-5 my-0 border-top">
    <div class="form-group">
      <label class="text-gray">Version:</label>
      <select class="custom-select" onchange="switchVersion(this);">
        
        
        <option selected>latest</option>
        
        
      </select>
    </div>
  </form>
  
</div>
      

      <div class="col-12 col-md-8 col-xl-9">
        <div class="container">
          <div class="row">
            <div class="col-10 offset-1 pb-5 documentation-source" role="main">
              
              
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<div class="section" id="Optimizing-Existing-Networks">
<h1>Optimizing Existing Networks<a class="headerlink" href="#Optimizing-Existing-Networks" title="Permalink to this headline">¶</a></h1>
<p>Nengo DL is not confined to opimizing custom made networks, it can also be used to make existing networks better, or achieve the same result with fewer neurons. What this example will show is how to train a circular convolution network.</p>
<p>Circular convolution is a key operation used to process <a class="reference external" href="http://compneuro.uwaterloo.ca/research/spa/semantic-pointer-architecture.html">semantic pointers</a>. By optimizing this smaller network, larger more complex networks that utilize circular convolution can benefit.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">nengo</span>
<span class="kn">import</span> <span class="nn">nengo_dl</span>
<span class="kn">from</span> <span class="nn">nengo.spa</span> <span class="kn">import</span> <span class="n">Vocabulary</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</pre></div>
</div>
</div>
<p>To properly train the network, we generate novel training data by randomly generating semantic pointers.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">gen_pointers</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">,</span> <span class="n">dims</span><span class="p">,</span> <span class="n">rng</span><span class="p">):</span>
    <span class="n">vocabulary</span> <span class="o">=</span> <span class="n">Vocabulary</span><span class="p">(</span><span class="n">dimensions</span><span class="o">=</span><span class="n">dims</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="n">rng</span><span class="p">,</span> <span class="n">max_similarity</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">):</span>
        <span class="c1"># keys start with A, second element starts with B, third starts with C</span>
        <span class="n">conv_key</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;C</span><span class="si">{</span><span class="n">v</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">point_key_1</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;A</span><span class="si">{</span><span class="n">v</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">pointer_1</span> <span class="o">=</span> <span class="n">vocabulary</span><span class="o">.</span><span class="n">create_pointer</span><span class="p">()</span>
        <span class="n">point_key_2</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;B</span><span class="si">{</span><span class="n">v</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">pointer_2</span> <span class="o">=</span> <span class="n">vocabulary</span><span class="o">.</span><span class="n">create_pointer</span><span class="p">()</span>
        <span class="n">vocabulary</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">point_key_1</span><span class="p">,</span> <span class="n">pointer_1</span><span class="p">)</span>
        <span class="n">vocabulary</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">point_key_2</span><span class="p">,</span> <span class="n">pointer_2</span><span class="p">)</span>
        <span class="n">vocabulary</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">conv_key</span><span class="p">,</span> <span class="n">vocabulary</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">point_key_2</span> <span class="o">+</span> <span class="s2">&quot;*&quot;</span> <span class="o">+</span> <span class="n">point_key_1</span><span class="p">))</span>

    <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">vocabulary</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;A</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">v</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">)])[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">vocabulary</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;B</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">v</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">)])[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">vocabulary</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;C</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">v</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">)])[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
    <span class="k">return</span> <span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">vocabulary</span>


<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">dimensions</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">test_a</span><span class="p">,</span> <span class="n">test_b</span><span class="p">,</span> <span class="n">test_c</span><span class="p">,</span> <span class="n">vocab</span> <span class="o">=</span> <span class="n">gen_pointers</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">dimensions</span><span class="p">,</span> <span class="n">rng</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>We want our optimized network to work with spiking LIF neurons, so we will use SoftLIFRate neurons (a differentiable approximation of LIF neurons) to train the network.</p>
<p>We’ll start with the <code class="docutils literal notranslate"><span class="pre">nengo.networks.CircularConvolution</span></code> network, where all the parameters are initialized using the standard Nengo methods, and then further optimize those parameters using deep learning training methods.</p>
<p>In this example only 5 neurons are used per dimension for the circular convolution. This is fewer than would typically be used in a Nengo model, but the enhanced performance enabled by the training process will allow the network to function well with this restricted number of neurons.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Network</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">rng</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mf">1e6</span><span class="p">))</span> <span class="k">as</span> <span class="n">net</span><span class="p">:</span>
    <span class="n">net</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="n">nengo</span><span class="o">.</span><span class="n">Ensemble</span><span class="p">]</span><span class="o">.</span><span class="n">neuron_type</span> <span class="o">=</span> <span class="n">nengo_dl</span><span class="o">.</span><span class="n">SoftLIFRate</span><span class="p">(</span><span class="n">sigma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">]</span><span class="o">.</span><span class="n">synapse</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># Get the raw vectors for the pointers using `vocab[&#39;A&#39;].v`</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">output</span><span class="o">=</span><span class="n">vocab</span><span class="p">[</span><span class="s2">&quot;A0&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">v</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">output</span><span class="o">=</span><span class="n">vocab</span><span class="p">[</span><span class="s2">&quot;B0&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">v</span><span class="p">)</span>

    <span class="c1"># Make the circular convolution network with 5 neurons per dimension</span>
    <span class="n">cconv</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">networks</span><span class="o">.</span><span class="n">CircularConvolution</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">dimensions</span><span class="o">=</span><span class="n">dimensions</span><span class="p">)</span>

    <span class="c1"># Connect the input nodes to the input slots `A` and `B` on the network</span>
    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">cconv</span><span class="o">.</span><span class="n">input_a</span><span class="p">)</span>
    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">cconv</span><span class="o">.</span><span class="n">input_b</span><span class="p">)</span>

    <span class="c1"># Probe the output</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Probe</span><span class="p">(</span><span class="n">cconv</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
    <span class="n">out_filtered</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Probe</span><span class="p">(</span><span class="n">cconv</span><span class="o">.</span><span class="n">output</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>We now run the network in its default state to get an idea of the baseline performance. Ideally the output would be clearly <code class="docutils literal notranslate"><span class="pre">C0</span></code>, the result of the convolution between <code class="docutils literal notranslate"><span class="pre">A0</span></code> and <code class="docutils literal notranslate"><span class="pre">B0</span></code>, but we can see that it is poorly differentiated.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Simulator</span><span class="p">(</span><span class="n">net</span><span class="p">)</span> <span class="k">as</span> <span class="n">sim</span><span class="p">:</span>
    <span class="n">sim</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">output_vocab</span> <span class="o">=</span> <span class="n">vocab</span><span class="o">.</span><span class="n">create_subset</span><span class="p">([</span><span class="sa">f</span><span class="s2">&quot;C</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">trange</span><span class="p">(),</span> <span class="n">nengo</span><span class="o">.</span><span class="n">spa</span><span class="o">.</span><span class="n">similarity</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">out_filtered</span><span class="p">],</span> <span class="n">output_vocab</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">output_vocab</span><span class="o">.</span><span class="n">keys</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;t [s]&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;dot product&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<script>
    if (Jupyter.version.split(".")[0] < 5) {
        var pb = document.getElementById("f7afd09e-c1b1-4b29-a31c-b1cc9cfa1b5b");
        var text = document.createTextNode(
            "HMTL progress bar requires Jupyter Notebook >= " +
            "5.0 or Jupyter Lab. Alternatively, you can use " +
            "TerminalProgressBar().");
        pb.parentNode.insertBefore(text, pb);
    }
</script>
<div id="f7afd09e-c1b1-4b29-a31c-b1cc9cfa1b5b" style="
    width: 100%;
    border: 1px solid #cfcfcf;
    border-radius: 4px;
    text-align: center;
    position: relative;">
  <div class="pb-text" style="
      position: absolute;
      width: 100%;">
    0%
  </div>
  <div class="pb-fill" style="
      background-color: #bdd2e6;
      width: 0%;">
    <style type="text/css" scoped="scoped">
        @keyframes pb-fill-anim {
            0% { background-position: 0 0; }
            100% { background-position: 100px 0; }
        }
    </style>
    &nbsp;
  </div>
</div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<script>
              (function () {
                  var root = document.getElementById('f7afd09e-c1b1-4b29-a31c-b1cc9cfa1b5b');
                  var text = root.getElementsByClassName('pb-text')[0];
                  var fill = root.getElementsByClassName('pb-fill')[0];

                  text.innerHTML = 'Build finished in 0:00:03.';

            fill.style.width = '100%';
            fill.style.animation = 'pb-fill-anim 2s linear infinite';
            fill.style.backgroundSize = '100px 100%';
            fill.style.backgroundImage = 'repeating-linear-gradient(' +
                '90deg, #bdd2e6, #edf2f8 40%, #bdd2e6 80%, #bdd2e6)';


                fill.style.animation = 'none';
                fill.style.backgroundImage = 'none';

              })();
        </script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/tbekolay/Code/nengo-dl/nengo_dl/neurons.py:77: RuntimeWarning: divide by zero encountered in true_divide
  q = np.where(j_valid, np.log1p(1 / z), -js - np.log(self.sigma))
/home/tbekolay/Code/nengo-dl/nengo_dl/neurons.py:77: RuntimeWarning: overflow encountered in true_divide
  q = np.where(j_valid, np.log1p(1 / z), -js - np.log(self.sigma))
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<script>
    if (Jupyter.version.split(".")[0] < 5) {
        var pb = document.getElementById("70f4722f-9d98-44e3-ba02-dee104ac41b0");
        var text = document.createTextNode(
            "HMTL progress bar requires Jupyter Notebook >= " +
            "5.0 or Jupyter Lab. Alternatively, you can use " +
            "TerminalProgressBar().");
        pb.parentNode.insertBefore(text, pb);
    }
</script>
<div id="70f4722f-9d98-44e3-ba02-dee104ac41b0" style="
    width: 100%;
    border: 1px solid #cfcfcf;
    border-radius: 4px;
    text-align: center;
    position: relative;">
  <div class="pb-text" style="
      position: absolute;
      width: 100%;">
    0%
  </div>
  <div class="pb-fill" style="
      background-color: #bdd2e6;
      width: 0%;">
    <style type="text/css" scoped="scoped">
        @keyframes pb-fill-anim {
            0% { background-position: 0 0; }
            100% { background-position: 100px 0; }
        }
    </style>
    &nbsp;
  </div>
</div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<script>
              (function () {
                  var root = document.getElementById('70f4722f-9d98-44e3-ba02-dee104ac41b0');
                  var text = root.getElementsByClassName('pb-text')[0];
                  var fill = root.getElementsByClassName('pb-fill')[0];

                  text.innerHTML = 'Simulation finished in 0:00:01.';

            if (100.0 > 0.) {
                fill.style.transition = 'width 0.1s linear';
            } else {
                fill.style.transition = 'none';
            }

            fill.style.width = '100.0%';
            fill.style.animation = 'none';
            fill.style.backgroundImage = 'none'


                fill.style.animation = 'none';
                fill.style.backgroundImage = 'none';

              })();
        </script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Text(0, 0.5, &#39;dot product&#39;)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/deeplearning_circularconvolution-softlif_7_6.png" src="../_images/deeplearning_circularconvolution-softlif_7_6.png" />
</div>
</div>
<p>Now we can optimize our network, by showing it random input pointers and training it to output their circular convolution.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">nengo_dl</span><span class="o">.</span><span class="n">Simulator</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">minibatch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;/cpu:0&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">sim</span><span class="p">:</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">RMSPropOptimizer</span><span class="p">(</span><span class="mf">5e-3</span><span class="p">)</span>

    <span class="c1"># generate random data</span>
    <span class="n">train_a</span><span class="p">,</span> <span class="n">train_b</span><span class="p">,</span> <span class="n">train_c</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">gen_pointers</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">dimensions</span><span class="p">,</span> <span class="n">rng</span><span class="p">)</span>
    <span class="n">input_feed</span> <span class="o">=</span> <span class="p">{</span><span class="n">a</span><span class="p">:</span> <span class="n">train_a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">train_b</span><span class="p">}</span>
    <span class="n">output_feed</span> <span class="o">=</span> <span class="p">{</span><span class="n">out</span><span class="p">:</span> <span class="n">train_c</span><span class="p">}</span>

    <span class="c1"># train the network for one epoch</span>
    <span class="n">sim</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;mse&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>
    <span class="n">sim</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">input_feed</span><span class="p">,</span> <span class="n">output_feed</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

    <span class="n">sim</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="mf">0.3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
|#####################Building network (40%)                     | ETA: 0:00:00
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/tbekolay/Code/nengo-dl/nengo_dl/neurons.py:75: RuntimeWarning: overflow encountered in exp
  z = np.where(js &gt; 30, js, np.log1p(np.exp(js))) * self.sigma
/home/tbekolay/Code/nengo-dl/nengo_dl/neurons.py:77: RuntimeWarning: divide by zero encountered in true_divide
  q = np.where(j_valid, np.log1p(1 / z), -js - np.log(self.sigma))
/home/tbekolay/Code/nengo-dl/nengo_dl/neurons.py:77: RuntimeWarning: overflow encountered in true_divide
  q = np.where(j_valid, np.log1p(1 / z), -js - np.log(self.sigma))
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Build finished in 0:00:01
Optimization finished in 0:00:00
|##############Constructing graph: build stage (63%)             | ETA: 0:00:00
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2022-01-21 11:48:39.546632: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Construction finished in 0:00:01
Epoch 1/100
|             Constructing graph: build stage (0%)             | ETA:  --:--:--
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/tbekolay/Code/nengo-dl/nengo_dl/simulator.py:1024: UserWarning: Running for one timestep, but the network contains synaptic filters (which will introduce at least a one-timestep delay); did you mean to set synapse=None?
  warnings.warn(
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
10/10 [==============================] - 2s 22ms/step - loss: 0.0260 - probe_loss: 0.0260 - probe_1_loss: 0.0000e+00
Epoch 2/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0191 - probe_loss: 0.0191 - probe_1_loss: 0.0000e+00
Epoch 3/100
10/10 [==============================] - 0s 21ms/step - loss: 0.0175 - probe_loss: 0.0175 - probe_1_loss: 0.0000e+00
Epoch 4/100
10/10 [==============================] - 0s 22ms/step - loss: 0.0251 - probe_loss: 0.0251 - probe_1_loss: 0.0000e+00
Epoch 5/100
10/10 [==============================] - 0s 24ms/step - loss: 0.0309 - probe_loss: 0.0309 - probe_1_loss: 0.0000e+00
Epoch 6/100
10/10 [==============================] - 0s 22ms/step - loss: 0.0304 - probe_loss: 0.0304 - probe_1_loss: 0.0000e+00
Epoch 7/100
10/10 [==============================] - 0s 22ms/step - loss: 0.0283 - probe_loss: 0.0283 - probe_1_loss: 0.0000e+00
Epoch 8/100
10/10 [==============================] - 0s 24ms/step - loss: 0.0253 - probe_loss: 0.0253 - probe_1_loss: 0.0000e+00
Epoch 9/100
10/10 [==============================] - 0s 24ms/step - loss: 0.0223 - probe_loss: 0.0223 - probe_1_loss: 0.0000e+00
Epoch 10/100
10/10 [==============================] - 0s 24ms/step - loss: 0.0211 - probe_loss: 0.0211 - probe_1_loss: 0.0000e+00
Epoch 11/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0190 - probe_loss: 0.0190 - probe_1_loss: 0.0000e+00
Epoch 12/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0176 - probe_loss: 0.0176 - probe_1_loss: 0.0000e+00
Epoch 13/100
10/10 [==============================] - 0s 22ms/step - loss: 0.0163 - probe_loss: 0.0163 - probe_1_loss: 0.0000e+00
Epoch 14/100
10/10 [==============================] - 0s 24ms/step - loss: 0.0160 - probe_loss: 0.0160 - probe_1_loss: 0.0000e+00
Epoch 15/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0147 - probe_loss: 0.0147 - probe_1_loss: 0.0000e+00
Epoch 16/100
10/10 [==============================] - 0s 22ms/step - loss: 0.0141 - probe_loss: 0.0141 - probe_1_loss: 0.0000e+00
Epoch 17/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0141 - probe_loss: 0.0141 - probe_1_loss: 0.0000e+00
Epoch 18/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0139 - probe_loss: 0.0139 - probe_1_loss: 0.0000e+00
Epoch 19/100
10/10 [==============================] - 0s 21ms/step - loss: 0.0136 - probe_loss: 0.0136 - probe_1_loss: 0.0000e+00
Epoch 20/100
10/10 [==============================] - 0s 22ms/step - loss: 0.0132 - probe_loss: 0.0132 - probe_1_loss: 0.0000e+00
Epoch 21/100
10/10 [==============================] - 0s 22ms/step - loss: 0.0130 - probe_loss: 0.0130 - probe_1_loss: 0.0000e+00
Epoch 22/100
10/10 [==============================] - 0s 21ms/step - loss: 0.0128 - probe_loss: 0.0128 - probe_1_loss: 0.0000e+00
Epoch 23/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0124 - probe_loss: 0.0124 - probe_1_loss: 0.0000e+00
Epoch 24/100
10/10 [==============================] - 0s 22ms/step - loss: 0.0122 - probe_loss: 0.0122 - probe_1_loss: 0.0000e+00
Epoch 25/100
10/10 [==============================] - 0s 21ms/step - loss: 0.0118 - probe_loss: 0.0118 - probe_1_loss: 0.0000e+00
Epoch 26/100
10/10 [==============================] - 0s 21ms/step - loss: 0.0121 - probe_loss: 0.0121 - probe_1_loss: 0.0000e+00
Epoch 27/100
10/10 [==============================] - 0s 20ms/step - loss: 0.0115 - probe_loss: 0.0115 - probe_1_loss: 0.0000e+00
Epoch 28/100
10/10 [==============================] - 0s 21ms/step - loss: 0.0111 - probe_loss: 0.0111 - probe_1_loss: 0.0000e+00
Epoch 29/100
10/10 [==============================] - 0s 22ms/step - loss: 0.0113 - probe_loss: 0.0113 - probe_1_loss: 0.0000e+00
Epoch 30/100
10/10 [==============================] - 0s 22ms/step - loss: 0.0112 - probe_loss: 0.0112 - probe_1_loss: 0.0000e+00
Epoch 31/100
10/10 [==============================] - 0s 22ms/step - loss: 0.0107 - probe_loss: 0.0107 - probe_1_loss: 0.0000e+00
Epoch 32/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0111 - probe_loss: 0.0111 - probe_1_loss: 0.0000e+00
Epoch 33/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0103 - probe_loss: 0.0103 - probe_1_loss: 0.0000e+00
Epoch 34/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0109 - probe_loss: 0.0109 - probe_1_loss: 0.0000e+00
Epoch 35/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0102 - probe_loss: 0.0102 - probe_1_loss: 0.0000e+00
Epoch 36/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0100 - probe_loss: 0.0100 - probe_1_loss: 0.0000e+00
Epoch 37/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0118 - probe_loss: 0.0118 - probe_1_loss: 0.0000e+00
Epoch 38/100
10/10 [==============================] - 0s 22ms/step - loss: 0.0095 - probe_loss: 0.0095 - probe_1_loss: 0.0000e+00
Epoch 39/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0096 - probe_loss: 0.0096 - probe_1_loss: 0.0000e+00
Epoch 40/100
10/10 [==============================] - 0s 24ms/step - loss: 0.0115 - probe_loss: 0.0115 - probe_1_loss: 0.0000e+00
Epoch 41/100
10/10 [==============================] - 0s 25ms/step - loss: 0.0093 - probe_loss: 0.0093 - probe_1_loss: 0.0000e+00
Epoch 42/100
10/10 [==============================] - 0s 22ms/step - loss: 0.0093 - probe_loss: 0.0093 - probe_1_loss: 0.0000e+00
Epoch 43/100
10/10 [==============================] - 0s 25ms/step - loss: 0.0104 - probe_loss: 0.0104 - probe_1_loss: 0.0000e+00
Epoch 44/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0091 - probe_loss: 0.0091 - probe_1_loss: 0.0000e+00
Epoch 45/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0103 - probe_loss: 0.0103 - probe_1_loss: 0.0000e+00
Epoch 46/100
10/10 [==============================] - 0s 21ms/step - loss: 0.0098 - probe_loss: 0.0098 - probe_1_loss: 0.0000e+00
Epoch 47/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0088 - probe_loss: 0.0088 - probe_1_loss: 0.0000e+00
Epoch 48/100
10/10 [==============================] - 0s 24ms/step - loss: 0.0105 - probe_loss: 0.0105 - probe_1_loss: 0.0000e+00
Epoch 49/100
10/10 [==============================] - 0s 24ms/step - loss: 0.0089 - probe_loss: 0.0089 - probe_1_loss: 0.0000e+00
Epoch 50/100
10/10 [==============================] - 0s 24ms/step - loss: 0.0089 - probe_loss: 0.0089 - probe_1_loss: 0.0000e+00
Epoch 51/100
10/10 [==============================] - 0s 25ms/step - loss: 0.0102 - probe_loss: 0.0102 - probe_1_loss: 0.0000e+00
Epoch 52/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0085 - probe_loss: 0.0085 - probe_1_loss: 0.0000e+00
Epoch 53/100
10/10 [==============================] - 0s 24ms/step - loss: 0.0086 - probe_loss: 0.0086 - probe_1_loss: 0.0000e+00
Epoch 54/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0116 - probe_loss: 0.0116 - probe_1_loss: 0.0000e+00
Epoch 55/100
10/10 [==============================] - 0s 24ms/step - loss: 0.0082 - probe_loss: 0.0082 - probe_1_loss: 0.0000e+00
Epoch 56/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0083 - probe_loss: 0.0083 - probe_1_loss: 0.0000e+00
Epoch 57/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0112 - probe_loss: 0.0112 - probe_1_loss: 0.0000e+00
Epoch 58/100
10/10 [==============================] - 0s 24ms/step - loss: 0.0081 - probe_loss: 0.0081 - probe_1_loss: 0.0000e+00
Epoch 59/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0082 - probe_loss: 0.0082 - probe_1_loss: 0.0000e+00
Epoch 60/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0100 - probe_loss: 0.0100 - probe_1_loss: 0.0000e+00
Epoch 61/100
10/10 [==============================] - 0s 21ms/step - loss: 0.0084 - probe_loss: 0.0084 - probe_1_loss: 0.0000e+00
Epoch 62/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0081 - probe_loss: 0.0081 - probe_1_loss: 0.0000e+00
Epoch 63/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0108 - probe_loss: 0.0108 - probe_1_loss: 0.0000e+00
Epoch 64/100
10/10 [==============================] - 0s 24ms/step - loss: 0.0078 - probe_loss: 0.0078 - probe_1_loss: 0.0000e+00
Epoch 65/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0080 - probe_loss: 0.0080 - probe_1_loss: 0.0000e+00
Epoch 66/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0107 - probe_loss: 0.0107 - probe_1_loss: 0.0000e+00
Epoch 67/100
10/10 [==============================] - 0s 24ms/step - loss: 0.0077 - probe_loss: 0.0077 - probe_1_loss: 0.0000e+00
Epoch 68/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0078 - probe_loss: 0.0078 - probe_1_loss: 0.0000e+00
Epoch 69/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0108 - probe_loss: 0.0108 - probe_1_loss: 0.0000e+00
Epoch 70/100
10/10 [==============================] - 0s 20ms/step - loss: 0.0076 - probe_loss: 0.0076 - probe_1_loss: 0.0000e+00
Epoch 71/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0078 - probe_loss: 0.0078 - probe_1_loss: 0.0000e+00
Epoch 72/100
10/10 [==============================] - 0s 24ms/step - loss: 0.0101 - probe_loss: 0.0101 - probe_1_loss: 0.0000e+00
Epoch 73/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0075 - probe_loss: 0.0075 - probe_1_loss: 0.0000e+00
Epoch 74/100
10/10 [==============================] - 0s 24ms/step - loss: 0.0078 - probe_loss: 0.0078 - probe_1_loss: 0.0000e+00
Epoch 75/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0102 - probe_loss: 0.0102 - probe_1_loss: 0.0000e+00
Epoch 76/100
10/10 [==============================] - 0s 24ms/step - loss: 0.0074 - probe_loss: 0.0074 - probe_1_loss: 0.0000e+00
Epoch 77/100
10/10 [==============================] - 0s 24ms/step - loss: 0.0084 - probe_loss: 0.0084 - probe_1_loss: 0.0000e+00
Epoch 78/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0093 - probe_loss: 0.0093 - probe_1_loss: 0.0000e+00
Epoch 79/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0074 - probe_loss: 0.0074 - probe_1_loss: 0.0000e+00
Epoch 80/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0088 - probe_loss: 0.0088 - probe_1_loss: 0.0000e+00
Epoch 81/100
10/10 [==============================] - 0s 21ms/step - loss: 0.0095 - probe_loss: 0.0095 - probe_1_loss: 0.0000e+00
Epoch 82/100
10/10 [==============================] - 0s 22ms/step - loss: 0.0072 - probe_loss: 0.0072 - probe_1_loss: 0.0000e+00
Epoch 83/100
10/10 [==============================] - 0s 20ms/step - loss: 0.0076 - probe_loss: 0.0076 - probe_1_loss: 0.0000e+00
Epoch 84/100
10/10 [==============================] - 0s 20ms/step - loss: 0.0098 - probe_loss: 0.0098 - probe_1_loss: 0.0000e+00
Epoch 85/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0071 - probe_loss: 0.0071 - probe_1_loss: 0.0000e+00
Epoch 86/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0077 - probe_loss: 0.0077 - probe_1_loss: 0.0000e+00
Epoch 87/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0099 - probe_loss: 0.0099 - probe_1_loss: 0.0000e+00
Epoch 88/100
10/10 [==============================] - 0s 24ms/step - loss: 0.0070 - probe_loss: 0.0070 - probe_1_loss: 0.0000e+00
Epoch 89/100
10/10 [==============================] - 0s 20ms/step - loss: 0.0082 - probe_loss: 0.0082 - probe_1_loss: 0.0000e+00
Epoch 90/100
10/10 [==============================] - 0s 22ms/step - loss: 0.0099 - probe_loss: 0.0099 - probe_1_loss: 0.0000e+00
Epoch 91/100
10/10 [==============================] - 0s 22ms/step - loss: 0.0070 - probe_loss: 0.0070 - probe_1_loss: 0.0000e+00
Epoch 92/100
10/10 [==============================] - 0s 20ms/step - loss: 0.0073 - probe_loss: 0.0073 - probe_1_loss: 0.0000e+00
Epoch 93/100
10/10 [==============================] - 0s 21ms/step - loss: 0.0098 - probe_loss: 0.0098 - probe_1_loss: 0.0000e+00
Epoch 94/100
10/10 [==============================] - 0s 22ms/step - loss: 0.0069 - probe_loss: 0.0069 - probe_1_loss: 0.0000e+00
Epoch 95/100
10/10 [==============================] - 0s 20ms/step - loss: 0.0078 - probe_loss: 0.0078 - probe_1_loss: 0.0000e+00
Epoch 96/100
10/10 [==============================] - 0s 22ms/step - loss: 0.0094 - probe_loss: 0.0094 - probe_1_loss: 0.0000e+00
Epoch 97/100
10/10 [==============================] - 0s 23ms/step - loss: 0.0070 - probe_loss: 0.0070 - probe_1_loss: 0.0000e+00
Epoch 98/100
10/10 [==============================] - 0s 24ms/step - loss: 0.0074 - probe_loss: 0.0074 - probe_1_loss: 0.0000e+00
Epoch 99/100
10/10 [==============================] - 0s 22ms/step - loss: 0.0101 - probe_loss: 0.0101 - probe_1_loss: 0.0000e+00
Epoch 100/100
10/10 [==============================] - 0s 22ms/step - loss: 0.0068 - probe_loss: 0.0068 - probe_1_loss: 0.0000e+00
Simulation finished in 0:00:03
</pre></div></div>
</div>
<p>After training we run the same test on the network and plot the output. Now we can clearly see that the output of the network is closest to the ideal output, <code class="docutils literal notranslate"><span class="pre">C0</span></code>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">output</span> <span class="o">=</span> <span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">out_filtered</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">trange</span><span class="p">(),</span> <span class="n">nengo</span><span class="o">.</span><span class="n">spa</span><span class="o">.</span><span class="n">similarity</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">output_vocab</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">output_vocab</span><span class="o">.</span><span class="n">keys</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;t [s]&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;dot product&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Text(0, 0.5, &#39;dot product&#39;)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/deeplearning_circularconvolution-softlif_11_1.png" src="../_images/deeplearning_circularconvolution-softlif_11_1.png" />
</div>
</div>
<p>In a future example we will show how to integrate these training improvements into a larger network and improve the performance of the network as a whole.</p>
</div>


            </div>
          </div>
        </div>
      </div>

    </div>
  </div>
</div><footer class="text-light footer-main gradient-bottom">
  <p class="small text-center mb-0">
    <a class="no-hover-line" href="https://appliedbrainresearch.com">
      <img
        src="https://appliedbrainresearch.com/img/logo-blue-notext.svg"
        height="48"
      />
    </a>
    <a href="https://www.nengo.ai/">What is Nengo?</a>
    <a href="https://www.nengo.ai/examples/">Examples</a>
    <a href="https://www.nengo.ai/documentation/">Documentation</a>
    <a href="https://www.nengo.ai/getting-started/">Getting started</a>
    <a href="https://www.nengo.ai/privacy/">Privacy</a>
  </p>
  <p class="small text-center mb-0">&copy; Applied Brain Research</p>
</footer>
<script>
  function switchVersion(select) {
    var option = select.selectedOptions[0];
    if (option.hasAttribute("value")) {
      window.location = option.value;
    }
  }
</script>

<script>
  var elements = document.querySelectorAll('.sidenav');
  Stickyfill.add(elements);
</script>
<script>
  ScrollReveal().reveal(".fade-in", {
      scale: 0.85,
      duration: 1000,
      delay: 250,
      interval: 50
  });
</script>
<script>
  $('a.toggle-sidenav').on('click', function(e) {
    e.preventDefault();
    if ( $(this).hasClass('active') ) {
      $(this).removeClass('active');
      $('.sidenav').removeClass('open');
    } else {
      $(this).addClass('active');
      $('.sidenav').addClass('open');
    }
  });
</script>
<script>
  var lists = document.querySelectorAll('.toctree ul');
  lists.forEach((ul) => {
      ul.classList.add("nav");
  });
  var links = document.querySelectorAll('.toctree a');
  links.forEach((link) => {
      link.classList.add("nav-link");
  });
  $("body").scrollspy({target: ".sidenav"});
</script>
  </body>
</html>