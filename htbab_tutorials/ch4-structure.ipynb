{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured Representations\n",
    "\n",
    "This model shows a method for constructing structured representations using semantic\n",
    "pointers (high dimensional vector representations). It uses a convolution network to\n",
    "bind two semantic pointers and a summation network to cojoin two semantic pointers.\n",
    "\n",
    "**Note**: This model can be simplified if built using the SPA (Semantic Pointer\n",
    "Architecture) package in Nengo 2.0. This method is shown in the last few sections of\n",
    "this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the environment\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import nengo\n",
    "from nengo.spa import Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Model\n",
    "This model has parameters as described in the book, with the ensembles having 20\n",
    "dimensions and 300 neurons each. You will use the `nengo.networks.CircularConvolution`\n",
    "class in Nengo 2.0 to compute the convolution (or binding) of two semantic pointers\n",
    "**A**\n",
    "and **B**.\n",
    "\n",
    "Since the collection of named vectors in a space forms a kind of \"vocabulary\" as\n",
    "described in the book, you will create a vocabulary to build structured representations\n",
    "out of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 20  # Number of dimensions\n",
    "n_neurons = 300  # Number of neurons in each ensemble\n",
    "\n",
    "# Creating a vocabulary\n",
    "rng = np.random.RandomState(0)\n",
    "vocab = Vocabulary(dimensions=dim, rng=rng)\n",
    "\n",
    "# Create the network object to which we can add ensembles, connections, etc.\n",
    "model = nengo.Network(label=\"Structured Representation\")\n",
    "with model:\n",
    "    # Input - Get the raw vectors for the pointers using `vocab['A'].v`\n",
    "    input_A = nengo.Node(output=vocab[\"A\"].v, label=\"Input A\")\n",
    "    input_B = nengo.Node(output=vocab[\"B\"].v, label=\"Input B\")\n",
    "\n",
    "    # Ensembles with 300 neurons and 20 dimensions\n",
    "    # Represents input_A\n",
    "    ens_A = nengo.Ensemble(n_neurons, dimensions=dim, label=\"A\")\n",
    "    # Represents input_B\n",
    "    ens_B = nengo.Ensemble(n_neurons, dimensions=dim, label=\"B\")\n",
    "\n",
    "    # Represents the convolution of A and B\n",
    "    ens_C = nengo.Ensemble(n_neurons, dimensions=dim, label=\"C\")\n",
    "    # Represents the sum of A and B\n",
    "    ens_sum = nengo.Ensemble(n_neurons, dimensions=dim, label=\"Sum\")\n",
    "\n",
    "    # Creating the circular convolution network with 70 neurons per dimension\n",
    "    net_bind = nengo.networks.CircularConvolution(70, dimensions=dim, label=\"Bind\")\n",
    "\n",
    "    # Connecting the input to ensembles A and B\n",
    "    nengo.Connection(input_A, ens_A)\n",
    "    nengo.Connection(input_B, ens_B)\n",
    "\n",
    "    # Projecting ensembles A and B to the Bind network\n",
    "    nengo.Connection(ens_A, net_bind.A)\n",
    "    nengo.Connection(ens_B, net_bind.B)\n",
    "    nengo.Connection(net_bind.output, ens_C)\n",
    "\n",
    "    # Projecting ensembles A and B to the Sum ensemble\n",
    "    nengo.Connection(ens_A, ens_sum)\n",
    "    nengo.Connection(ens_B, ens_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Probes to Collect Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anything that is probed will collect the data it produces over time, allowing you to\n",
    "analyze and visualize it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    A_probe = nengo.Probe(ens_A, synapse=0.03)\n",
    "    B_probe = nengo.Probe(ens_B, synapse=0.03)\n",
    "    C_probe = nengo.Probe(ens_C, synapse=0.03)\n",
    "    Sum_probe = nengo.Probe(ens_sum, synapse=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set `C` to equal the convolution of `A` with `B` in the vocabulary.\n",
    "# This will be your ground-truth to test the accuracy of the neural network.\n",
    "vocab.add(\"C\", vocab.parse(\"A * B\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run the model without `nengo_gui`, you have to create a Nengo simulator.\n",
    "Then, you\n",
    "can run that simulator over and over again without affecting the original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nengo.Simulator(model) as sim:  # Create the simulator\n",
    "    sim.run(1.0)  # Run it for one second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 3))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(sim.trange(), sim.data[A_probe])\n",
    "plt.title(\"Decoded Ensemble A\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(sim.trange(), sim.data[B_probe])\n",
    "plt.title(\"Decoded Ensemble B\")\n",
    "\n",
    "plt.figure(figsize=(14, 3))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(sim.trange(), sim.data[Sum_probe])\n",
    "plt.title(\"Sum (cojoin)\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(sim.trange(), sim.data[C_probe])\n",
    "plt.title(\"C (convolution)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graphs above show the value of individual components of their respective ensembles.\n",
    "They show the same information as the \"value\" graphs in the Interactive Plots in Nengo\n",
    "1.4 GUI as described in the book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the results\n",
    "\n",
    "The Interactive Plots in Nengo 1.4 GUI can also be used to see the \"Semantic Pointer\"\n",
    "graph of an ensemble as described in the book. You can create similarity graphs to get\n",
    "the same information by plotting the similarity between the semantic pointer represented\n",
    "by an ensemble and all the semantic pointers in the vocabulary. The dot product is a\n",
    "common measure of similarity between semantic pointers, since it approximates the cosine\n",
    "similarity when the semantic pointer lengths are close to one.\n",
    "\n",
    "For this model, you can plot the exact convolution of the semantic pointers **A** and\n",
    "**B** (given by\n",
    "`vocab.parse('A * B')`), and the result of the neural convolution (given by\n",
    "`sim.data[C_probe]`).\n",
    "\n",
    "Both the dot product and the exact cosine similarity can be computed with\n",
    "`nengo.spa.similarity`. Normally, this function will compute the dot product, but\n",
    "setting `normalize=True` normalizes all vectors so that the exact cosine similarity is\n",
    "computed instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sim.trange(), nengo.spa.similarity(sim.data[C_probe], vocab))\n",
    "plt.legend(vocab.keys, loc=4)\n",
    "plt.xlabel(\"t [s]\")\n",
    "plt.ylabel(\"dot product\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot shows that the neural output is much closer to `C = A * B` than to either\n",
    "`A` or `B`, suggesting that the network is correctly computing the convolution. The dot\n",
    "product between the neural output and `C` is not exactly one due in large part to the\n",
    "fact that the length of `C` is not exactly one. Using cosine similarity, this magnitude\n",
    "difference can be neglected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sim.trange(), nengo.spa.similarity(sim.data[C_probe], vocab, normalize=True))\n",
    "plt.legend(vocab.keys, loc=4)\n",
    "plt.xlabel(\"t [s]\")\n",
    "plt.ylabel(\"cosine similarity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the cosine similarity between the neural output vectors and `C` is\n",
    "almost exactly one, demonstrating that the neural population is quite accurate in\n",
    "computing the convolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model using the `nengo.spa` package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will build this model again, using the `nengo.spa`\n",
    "package built into Nengo 2.0. You will see that using the `spa` package considerably\n",
    "simplifies model construction and visualization through `nengo_gui`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nengo import spa\n",
    "\n",
    "dim = 32  # the dimensionality of the vectors\n",
    "\n",
    "# Creating a vocabulary\n",
    "rng = np.random.RandomState(0)\n",
    "vocab = Vocabulary(dimensions=dim, rng=rng)\n",
    "vocab.add(\"C\", vocab.parse(\"A * B\"))\n",
    "\n",
    "# Create the spa.SPA network to which we can add SPA objects\n",
    "model = spa.SPA(label=\"structure\", vocabs=[vocab])\n",
    "with model:\n",
    "    model.A = spa.State(dim)\n",
    "    model.B = spa.State(dim)\n",
    "    model.C = spa.State(dim, feedback=1)\n",
    "    model.Sum = spa.State(dim)\n",
    "\n",
    "    actions = spa.Actions(\"C = A * B\", \"Sum = A\", \"Sum = B\")\n",
    "\n",
    "    model.cortical = spa.Cortical(actions)\n",
    "\n",
    "    # Model input\n",
    "    model.input = spa.Input(A=\"A\", B=\"B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model in nengo_gui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the `nengo_gui` visualizer to run and visualize the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nengo_gui.ipython import IPythonViz\n",
    "\n",
    "IPythonViz(model, \"ch4-structure.py.cfg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Press the play button in the visualizer to run the simulation. You should see the\n",
    "\"Semantic pointer cloud\" graphs as shown in the figure below.\n",
    "\n",
    "The graphs `A` and `B` show the semantic pointer representations in objects **A** and\n",
    "**B**\n",
    "respectively. Graphs labelled `C` show the result of the convolution operation (left:\n",
    "shows the semantic pointer representation in object `C`, right: shows the similarity\n",
    "with the vectors in the vocabulary). The graphs labelled `Sum` show the sum of A and B\n",
    "as represented by the object `Sum` (left: shows the semantic pointer representation in\n",
    "Sum, right: shows high similarity with vectors **A** and **B**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(filename=\"ch4-structure.png\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
